{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMF0m1+Fyi+ZyBMDWZ1cT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharky1746/20-1-Visual-Artificial-Intelligence/blob/main/%ED%85%8C%EC%98%A4%EB%B1%85%EC%A7%84_%EA%B8%B0%EB%A7%90_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-O6hoWePlWa",
        "outputId": "a3d1e3d9-17a3-44d7-800c-5b51f04e906a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None,784])\n",
        "\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "########## CNN\n",
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "def weight_variable(shape):\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(initial)\n",
        "def bias_variable(shape):\n",
        "  initial = tf.constant(0.1, shape=shape)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "x_image = tf.reshape(x,[-1, 28, 28, 1])\n",
        "\n",
        "W_conv1 = weight_variable([5, 5, 1, 20])\n",
        "b_conv1 = bias_variable([20])\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)\n",
        "\n",
        "\n",
        "W_conv2 = weight_variable([5, 5, 20, 50])\n",
        "b_conv2 = bias_variable([50])\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)\n",
        "\n",
        "'''\n",
        "\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*50])\n",
        "W_fc1 = weight_variable([7*7*50, 500])\n",
        "b_fc1 = bias_variable([500])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "W_fc2 = weight_variable([500, 10])\n",
        "b_fc2 = bias_variable([10])\n",
        "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
        "\n",
        "'''\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*50])\n",
        "W_fc1 = weight_variable([7*7*50, 10])\n",
        "b_fc1 = bias_variable([10])\n",
        "y_conv = tf.nn.softmax(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*50])\n",
        "W_fc1 = weight_variable([7*7*50, 500])\n",
        "b_fc1 = bias_variable([500])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "W_fc2 = weight_variable([500, 10])\n",
        "b_fc2 = bias_variable([10])\n",
        "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "cross_entropy_CNN = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
        "train_step_CNN = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy_CNN)\n",
        "\n",
        "correct_prediction_CNN = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
        "accuracy_CNN = tf.reduce_mean(tf.cast(correct_prediction_CNN, tf.float32))\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for i in range(2000):\n",
        "  batch = mnist.train.next_batch(50)\n",
        "  sess.run(train_step_CNN, feed_dict= {x: batch[0], y: batch[1] })\n",
        "  if i % 100 == 0:\n",
        "    train_accuracy_CNN = accuracy_CNN.eval(feed_dict= {x: batch[0], y: batch[1]} )\n",
        "    print('[CNN] step %d, training accuracy %g' % (i, train_accuracy_CNN))\n",
        "\n",
        "print('[CNN] test accuracy %g'%accuracy_CNN.eval(feed_dict={ x: mnist.test.images, y:mnist.test.labels} ))\n",
        "\n",
        "print(history.history.keys())\n",
        "#  \"Accuracy\"\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CNN] step 0, training accuracy 0.1\n",
            "[CNN] step 100, training accuracy 0.46\n",
            "[CNN] step 200, training accuracy 0.66\n",
            "[CNN] step 300, training accuracy 0.7\n",
            "[CNN] step 400, training accuracy 0.72\n",
            "[CNN] step 500, training accuracy 0.78\n",
            "[CNN] step 600, training accuracy 0.68\n",
            "[CNN] step 700, training accuracy 0.7\n",
            "[CNN] step 800, training accuracy 0.64\n",
            "[CNN] step 900, training accuracy 0.6\n",
            "[CNN] step 1000, training accuracy 0.78\n",
            "[CNN] step 1100, training accuracy 0.86\n",
            "[CNN] step 1200, training accuracy 0.84\n",
            "[CNN] step 1300, training accuracy 0.72\n",
            "[CNN] step 1400, training accuracy 0.74\n",
            "[CNN] step 1500, training accuracy 0.76\n",
            "[CNN] step 1600, training accuracy 0.74\n",
            "[CNN] step 1700, training accuracy 0.9\n",
            "[CNN] step 1800, training accuracy 0.74\n",
            "[CNN] step 1900, training accuracy 0.86\n",
            "[CNN] test accuracy 0.8536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cf4fb8594a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[CNN] test accuracy %g'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0maccuracy_CNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;31m#  \"Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    }
  ]
}
